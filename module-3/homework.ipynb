{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31e3908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mage-ai\n",
      "Version: 0.9.76\n",
      "Summary: Mage is a tool for building and deploying data pipelines.\n",
      "Home-page: https://github.com/mage-ai/mage-ai\n",
      "Author: Mage\n",
      "Author-email: eng@mage.ai\n",
      "License: \n",
      "Location: c:\\users\\lenovo\\practicals\\3_ml_ops\\.venv\\lib\\site-packages\n",
      "Requires: aiofiles, aiohttp, alembic, bcrypt, cachetools, croniter, cryptography, dask, datadog, Faker, freezegun, GitPython, great-expectations, httpx, inflection, ipykernel, ipython, itsdangerous, Jinja2, joblib, jupyter-server, jupyter_client, ldap3, memory_profiler, newrelic, numpy, pandas, Pillow, polars, protobuf, psutil, pyairtable, pyarrow, PyGithub, PyJWT, python-dateutil, pytz, pyyaml, redis, requests, ruamel.yaml, scikit-learn, sentry-sdk, setuptools, simplejson, six, sqlalchemy, sqlglot, terminado, thefuzz, tornado, typer, typing_extensions, watchdog, Werkzeug\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show mage-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data.py\n",
    "\n",
    "import pandas as pd\n",
    "from mage_ai.io.file import FileIO\n",
    "if 'data_loader' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_loader\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "\n",
    "@data_loader\n",
    "def load_data_from_file(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Load March 2023 Yellow Taxi data from parquet file.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(\n",
    "        'C:/Users/3_ML_OPS/03-orchestration/data/yellow_tripdata_2023-03.parquet'\n",
    "    )\n",
    "    print(f'✅ Loaded data with shape: {df.shape}')\n",
    "    return df\n",
    "\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    assert output.shape[0] == 3403766, 'Row count mismatch!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f25c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_data.py\n",
    "\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@transformer\n",
    "def prepare_data(df_raw: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transformer block to clean and filter NYC Yellow Taxi data.\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Calculate trip duration in minutes\n",
    "    df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "    df['duration'] = df['duration'].dt.total_seconds() / 60\n",
    "\n",
    "    # Filter out trips with duration less than 1 or more than 60 mins\n",
    "    df = df[(df['duration'] >= 1) & (df['duration'] <= 60)]\n",
    "\n",
    "    # Convert location IDs to strings (categorical)\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    print(f\" ✅ Filtered data shape: {df.shape}\")  # Print number of rows and columns\n",
    "\n",
    "    return df\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Basic tests for filtered DataFrame\n",
    "    \"\"\"\n",
    "    assert output is not None, 'Output is None'\n",
    "    assert 'duration' in output.columns, 'Missing duration column'\n",
    "    assert output['duration'].between(1, 60).all(), 'Duration filter failed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.py\n",
    "\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@transformer\n",
    "def train_model(df: pd.DataFrame, *args, **kwargs):\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Dicts for DictVectorizer\n",
    "    dicts = df[categorical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    y_train = df['duration'].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ✅ Print intercept for homework\n",
    "    print(f\"✅ Intercept: {model.intercept_:.2f}\")\n",
    "\n",
    "    return model, dv\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Template code for testing the output of the block.\n",
    "    \"\"\"\n",
    "    assert output is not None, 'The output is undefined'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9af11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow logging\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"homework_module-3\")\n",
    "\n",
    "@transformer\n",
    "def train_model(df, *args, **kwargs):\n",
    "\n",
    "\n",
    "    # Prepare the data\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    train_dicts = df[categorical].to_dict(orient='records')\n",
    "    X = dv.fit_transform(train_dicts)\n",
    "    y = df['duration'].values\n",
    "\n",
    "    # Train/test split (not strictly required, but useful)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"✅ Intercept: {model.intercept_:.2f}\")\n",
    "\n",
    "    # Log model to MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "        mlflow.log_param(\"features\", categorical)\n",
    "        mlflow.log_metric(\"intercept\", model.intercept_)\n",
    "\n",
    "        # Save model and vectorizer\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "        #mlflow.log_artifact(local_path=\"dict_vectorizer.pkl\")\n",
    "\n",
    "    return model, dv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
